# üåê PolyIA ‚Äî Tutor Inteligente de Idiomas

Una aplicaci√≥n Full-Stack para aprender idiomas con IA h√≠brida:

- **Lecciones y actividades** generadas por una API en la nube (OpenAI GPT, Anthropic Claude o Google Gemini).
- **Chat en tiempo real** con correcci√≥n gramatical ejecutado por un modelo de lenguaje local (SLM) v√≠a Ollama.

---

## üèóÔ∏è Stack Tecnol√≥gico

| Capa       | Tecnolog√≠a                                           |
| ---------- | ---------------------------------------------------- |
| Frontend   | React 18 + Vite + Tailwind CSS + React Router v6     |
| Backend    | Python 3.11+ ¬∑ FastAPI ¬∑ SQLAlchemy ¬∑ JWT auth       |
| Base de datos | PostgreSQL 16 (Docker)                            |
| IA en la nube | OpenAI GPT-4o-mini / Claude 3 Haiku / Gemini 1.5 Flash |
| IA local   | Ollama + Qwen 2.5 (3 B) ‚Äî corre en tu m√°quina       |

---

## üìÅ Estructura del Proyecto

```
PolyIA/
‚îú‚îÄ‚îÄ docker-compose.yml          # Levanta PostgreSQL
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ frontend/                   # React + Vite + Tailwind
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.js
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js
‚îÇ   ‚îú‚îÄ‚îÄ postcss.config.js
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ main.jsx
‚îÇ       ‚îú‚îÄ‚îÄ index.css
‚îÇ       ‚îú‚îÄ‚îÄ App.jsx             # Rutas protegidas
‚îÇ       ‚îú‚îÄ‚îÄ context/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ AuthContext.jsx # Auth global (JWT)
‚îÇ       ‚îú‚îÄ‚îÄ services/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ api.js          # Axios configurado
‚îÇ       ‚îî‚îÄ‚îÄ components/
‚îÇ           ‚îú‚îÄ‚îÄ LoginForm.jsx   # Login + Registro
‚îÇ           ‚îú‚îÄ‚îÄ Dashboard.jsx   # Panel principal + lecciones
‚îÇ           ‚îî‚îÄ‚îÄ ChatTutor.jsx   # Chat con tutor local
‚îî‚îÄ‚îÄ backend/                    # FastAPI
    ‚îú‚îÄ‚îÄ main.py                 # App, CORS, endpoints
    ‚îú‚îÄ‚îÄ database.py             # Conexi√≥n SQLAlchemy
    ‚îú‚îÄ‚îÄ models.py               # Tablas ORM
    ‚îú‚îÄ‚îÄ schemas.py              # Pydantic schemas
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ .env.example
```
---

## üöÄ Instalaci√≥n y Ejecuci√≥n Local

### Prerrequisitos

- [Node.js 20+](https://nodejs.org/)
- [Python 3.11+](https://www.python.org/)
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) (para PostgreSQL)
- [Ollama](https://ollama.com/) *(opcional ‚Äî para el chat local)*
- Al menos una API key de: [OpenAI](https://platform.openai.com/), [Anthropic](https://console.anthropic.com/) o [Google AI Studio](https://aistudio.google.com/)

---

### Paso 1 ‚Äî Clonar el repositorio

```bash
git clone https://github.com/clonozxd/PolyIA.git
cd PolyIA
```

---

### Paso 2 ‚Äî Levantar la base de datos (PostgreSQL con Docker)

```bash
docker compose up -d
```

Verifica que el contenedor est√© corriendo:

```bash
docker compose ps
```

> La base de datos queda disponible en `localhost:5432` con las credenciales por defecto `polyia / polyia_secret`.

---

### Windows ‚Äî Iniciar (tras la instalaci√≥n)

Si ya instalaste dependencias, creaste el `.env` y configuraste todo, estos son los comandos m√≠nimos para arrancar la app en Windows (PowerShell). Ejecuta cada comando en terminales separadas cuando corresponda.

- Levantar la base de datos (si est√° apagada):

```powershell
cd C:\ruta\a\tu\repo\PolyIA   # o navega a la carpeta del proyecto
docker compose up -d
```

- Iniciar el backend (terminal separada):

```powershell
cd C:\ruta\a\tu\repo\PolyIA\backend
& ".venv\Scripts\Activate.ps1"    # activar venv
$env:PYTHONUTF8 = "1"
$env:PGCLIENTENCODING = "UTF8"
python -m uvicorn main:app --reload --port 8000
```

- Iniciar el frontend (otra terminal):

```powershell
cd C:\ruta\a\tu\repo\PolyIA\frontend
npm run dev
```

Accede a la aplicaci√≥n en `http://localhost:5173` y a la API en `http://localhost:8000`.

Si necesitas detener todo r√°pidamente:

```powershell
docker compose down
# Ctrl+C en las terminales donde corren uvicorn y vite
```


### Paso 3 ‚Äî Configurar y ejecutar el Backend

```bash
cd backend

# Crear y activar el entorno virtual
python -m venv .venv
source .venv/bin/activate      # macOS/Linux
# .venv\Scripts\activate       # Windows

# Instalar dependencias
pip install -r requirements.txt

# Copiar y editar las variables de entorno
cp .env.example .env
```

Edita `backend/.env` y rellena al menos una API key:

```env
DATABASE_URL=postgresql://polyia:polyia_secret@localhost:5432/polyia_db
SECRET_KEY=cambia-esto-por-una-cadena-aleatoria-larga

# Pon la(s) API key(s) de los proveedores que quieras usar:
OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# GOOGLE_API_KEY=AIza...
```

Iniciar el servidor:

```bash
uvicorn main:app --reload --port 8000
```

La API estar√° disponible en `http://localhost:8000`.  
Documentaci√≥n interactiva: `http://localhost:8000/docs`

---

### Paso 4 ‚Äî Configurar y ejecutar el Frontend

```bash
cd ../frontend

# Instalar dependencias
npm install

# (Opcional) Copiar variables de entorno
cp .env.example .env

# Iniciar en modo desarrollo
npm run dev
```

La aplicaci√≥n estar√° disponible en **`http://localhost:5173`**.

---

### Paso 5 ‚Äî (Opcional) Modelo local con Ollama

Para activar el chat con correcci√≥n gramatical usando el SLM local:

```bash
# Instalar Ollama desde https://ollama.com
ollama pull qwen2.5:3b   # descarga el modelo (~2 GB)
ollama serve             # inicia el servidor en localhost:11434
```

El backend detecta Ollama autom√°ticamente. Si no est√° disponible, el endpoint `/api/chat/local` devuelve un mensaje indicando c√≥mo activarlo.

---

## üß™ Resumen de comandos

| Acci√≥n                        | Comando                                     |
| ----------------------------- | ------------------------------------------- |
| Levantar DB                   | `docker compose up -d`                      |
| Iniciar backend               | `uvicorn main:app --reload --port 8000`     |
| **Iniciar frontend**          | **`npm run dev`** (desde `/frontend`)       |
| Build de producci√≥n frontend  | `npm run build` (desde `/frontend`)         |
| Bajar DB                      | `docker compose down`                       |

---

## üì° Endpoints de la API

| M√©todo | Ruta                      | Descripci√≥n                                 | Auth requerida |
| ------ | ------------------------- | ------------------------------------------- | -------------- |
| POST   | `/api/auth/register`      | Registro de nuevo usuario                   | No             |
| POST   | `/api/auth/login`         | Login ‚Äî devuelve JWT                        | No             |
| GET    | `/api/auth/me`            | Perfil del usuario autenticado              | ‚úÖ JWT          |
| POST   | `/api/leccion/generar`    | Genera lecci√≥n v√≠a IA en la nube            | ‚úÖ JWT          |
| GET    | `/api/leccion/lista`      | Lista lecciones del usuario                 | ‚úÖ JWT          |
| POST   | `/api/chat/local`         | Chat con SLM local + correcci√≥n gramatical  | ‚úÖ JWT          |
| GET    | `/health`                 | Health-check del servidor                   | No             |

---

## üóÑÔ∏è Schema de la Base de Datos (PostgreSQL)

Ejecuta este SQL directamente en tu instancia de PostgreSQL si prefieres crear las tablas manualmente en lugar de dejar que SQLAlchemy las cree autom√°ticamente al iniciar el backend.

```sql
-- ============================================================
-- PolyIA ‚Äì Database Schema
-- Compatible con PostgreSQL 14+
-- ============================================================

-- ‚îÄ‚îÄ Extensiones ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CREATE EXTENSION IF NOT EXISTS "pgcrypto";

-- ‚îÄ‚îÄ Tabla: usuarios ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CREATE TABLE IF NOT EXISTS usuarios (
    id               SERIAL PRIMARY KEY,
    email            VARCHAR(255) NOT NULL UNIQUE,
    hashed_password  VARCHAR(255) NOT NULL,
    nivel_idioma     VARCHAR(50)  NOT NULL DEFAULT 'principiante',
    is_active        BOOLEAN      NOT NULL DEFAULT TRUE,
    created_at       TIMESTAMPTZ  NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS ix_usuarios_email ON usuarios (email);

-- ‚îÄ‚îÄ Tabla: lecciones ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CREATE TABLE IF NOT EXISTS lecciones (
    id           SERIAL PRIMARY KEY,
    tema         VARCHAR(255) NOT NULL,
    contenido    TEXT         NOT NULL,
    proveedor_ia VARCHAR(50)  NOT NULL DEFAULT 'openai',
    created_at   TIMESTAMPTZ  NOT NULL DEFAULT NOW(),
    usuario_id   INTEGER      NOT NULL
        REFERENCES usuarios (id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS ix_lecciones_usuario ON lecciones (usuario_id);

-- ‚îÄ‚îÄ Tabla: mensajes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CREATE TABLE IF NOT EXISTS mensajes (
    id            SERIAL PRIMARY KEY,
    texto_usuario TEXT        NOT NULL,
    respuesta_ia  TEXT,
    correccion_ia TEXT,
    created_at    TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    usuario_id    INTEGER     NOT NULL
        REFERENCES usuarios (id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS ix_mensajes_usuario ON mensajes (usuario_id);
```

> **Nota:** Si arrancas el backend normalmente con `uvicorn main:app --reload`, SQLAlchemy ejecutar√° `CREATE TABLE IF NOT EXISTS` autom√°ticamente, por lo que **no necesitas correr este SQL manualmente** a menos que quieras inspeccionar o pre-crear el esquema.

---

## üîí Variables de Entorno

### Backend (`backend/.env`)

| Variable                    | Descripci√≥n                                          | Ejemplo / Default                                         |
| --------------------------- | ---------------------------------------------------- | --------------------------------------------------------- |
| `DATABASE_URL`              | Cadena de conexi√≥n PostgreSQL                        | `postgresql://polyia:polyia_secret@localhost:5432/polyia_db` |
| `SECRET_KEY`                | Secreto para firmar los JWT ‚Äî **c√°mbialo**           | string aleatorio largo                                    |
| `ACCESS_TOKEN_EXPIRE_MINUTES` | Duraci√≥n del token JWT                             | `60`                                                      |
| `ALLOWED_ORIGINS`           | Or√≠genes CORS permitidos (coma-separados)            | `http://localhost:5173`                                   |
| `OPENAI_API_KEY`            | API key de OpenAI                                    | `sk-...`                                                  |
| `OPENAI_MODEL`              | Modelo de OpenAI a usar                              | `gpt-4o-mini`                                             |
| `ANTHROPIC_API_KEY`         | API key de Anthropic (Claude)                        | `sk-ant-...`                                              |
| `ANTHROPIC_MODEL`           | Modelo de Anthropic a usar                           | `claude-3-haiku-20240307`                                 |
| `GOOGLE_API_KEY`            | API key de Google AI                                 | `AIza...`                                                 |
| `GOOGLE_MODEL`              | Modelo de Gemini a usar                              | `gemini-1.5-flash`                                        |
| `LOCAL_MODEL_URL`           | URL del servidor Ollama                              | `http://localhost:11434/api/generate`                     |
| `LOCAL_MODEL_NAME`          | Nombre del modelo Ollama                             | `qwen2.5:3b`                                              |

### Frontend (`frontend/.env`)

| Variable            | Descripci√≥n                                                   | Default |
| ------------------- | ------------------------------------------------------------- | ------- |
| `VITE_API_BASE_URL` | URL base del backend (vac√≠o = Vite proxy en desarrollo)       | *(vac√≠o)* |

---

## üîÆ Escalabilidad Futura

- **Alembic**: La carpeta `backend/` est√° lista para a√±adir migraciones con `alembic init alembic`.
- **Async FastAPI**: Cambia `create_engine` por `create_async_engine` + `asyncpg` para I/O completamente as√≠ncrono.
- **Streaming**: Los endpoints de lecci√≥n y chat pueden devolver `StreamingResponse` para mostrar la respuesta token por token.
- **Actividades/Cursos**: A√±ade nuevas tablas (`Curso`, `Actividad`) y endpoints siguiendo el mismo patr√≥n de `Leccion`.
- **WebSockets**: El endpoint de chat puede migrar a WebSocket para latencia a√∫n menor.
- **Redis**: Cachea las lecciones generadas para evitar llamadas repetidas a la API de la nube.
